---
title: "Homework 1"
author: "Ben Buzzee"
date: "September 3, 2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(BSDA)
```

# 1. Plasma Growth Hormone Measurements and the KS test

```{r data1}
A <- c(3.6, 2.6, 4.7, 8.0, 3.1, 8.8, 4.6, 5.8, 4.0, 4.6)

B <- c(16.2, 17.4, 8.5, 15.6, 5.4, 9.8, 14.9, 16.6, 15.9, 5.3, 10.5)
```
## a)
```{r ecdfs}
plot(ecdf(A), verticals = T, xlim = c(2,20), col = "red", main = "ECDFs")
lines(ecdf(B), verticals = T, col = "blue")
legend(15, .3, legend = c("Type A", "Type B"), col = c("red", "blue"), lty = 1)
```


The two samples appear to be very different, which seems to indicate there is a difference in outcomes for coronary-prone individuals compared with coronary resistant ones.

## b)

We will conduct a two-sample KS test using the above data. Our null hypothesis is that the two samples were generated by the same distribution function, or $H_0: F(t) = G(t) \ vs \ H_A: F(t) \neq G(t)$


```{r}
ks.test(A, B)
```

With a test statistic of .727 and p-value of .007 we would reject the null hypothesis and have strong evidence that the two data generating distributions are different.


# 2. Kolmogorov-Smirnov Simulation

## a)

```{r, echo = TRUE}
KSdist.sim = function(n, mu, sd, nreps)
{
  D.true=rep(NA, nreps)
  D.est=rep(NA, nreps)
  for (i in 1:nreps)
  {
    x=rnorm(n, mu, sd)
    D.true[i]=ks.test(x, "pnorm", mu, sd)$statistic
    D.est[i]=ks.test(x, "pnorm", mean(x), sd(x))$statistic
  }
  out=data.frame(D.true, D.est)
  out
}

```

Looking over the function, it appears to generate a normally distributed sample given the input parameters, then conducts two one-sample KS tests. The first KS test assumes we know the value of the parameters for the normal distribution, and the second estimates the values of the parameters before performing the test.

## b & c) 

```{r}
x <- KSdist.sim(n=50, mu = 3, sd = 4, nreps = 5000)

# head(x)


plot(density(x$D.true), main = "Test Statistic Densities, n = 50", col = "red", ylim = c(0, 25))
lines(density(x$D.est), col = "blue")
legend("topright", legend = c("True", "Estimates"), col = c("red", "blue"), lty = 1)
```


## d)

We see that the distribution of the test statistics using estimated parameters has a smaller variance than the distribution using the true values. This means our p-values would tend to be smaller and we would incorrectly reject the null hypothesis more often. In other words our type 1 error rate would be higher than we expected.


## e)

```{r}
x <- KSdist.sim(n=5000, mu = 3, sd = 4, nreps = 5000)

# head(x)


plot(density(x$D.true), main = "Test Statistic Densities, n = 5000", col = "red", ylim = c(0, 200))
lines(density(x$D.est), col = "blue")
legend("topright", legend = c("True", "Estimates"), col = c("red", "blue"), lty = 1)
```

Increasing the sample size to 5000 significantly reduces the variance of both distributions. It does not change the fact that the distribution using estimated parameters increases the probability of a type 1 error. The general shape and relative positioning of the distributions has also stayed the same.


# 3. Bleed Times and Sign Test

a) We are interested in whether bleeding times were longer immediately after ingesting 600 mg of aspirin (X) in comparison to bleed times 2 hours after ingestion (Y). First we will take a look at the data to make sure there are no outliers or strange observations.

```{r data3}
bleeding <- read.csv("bleeding.txt", sep = " ")

X <- bleeding$X
Y <- bleeding$Y

plot(X, type = "p", col = "red", ylim = c(100,700), main = "Bleed Times", ylab = "Time")
points(Y, col = "blue")
legend("topright", legend = c("X", "Y"), col = c("red", "blue"), pch  = 1)
```




For our sign test, our hypothesis statements are $H_0:M_X \leq M_Y \ vs \ H_A: M_X > M_Y$ for median bleed times $M_X$ and $M_Y$.
```{r}
SIGN.test(X, Y, alternative = "greater")
```


With a test statistic of 4 and p-value of .97, we have no evidence bleed times are longer immmediately after ingesting compared with bleed times 2 hours after ingestion.

## b)

```{r}
n <-  14

B <-  4


test_stat <- (B-n/2)/(sqrt(n)*.5)


1 - pnorm(test_stat)

```


Using the normal approximation, we arrive at a test statistic of -1.60 and a p-value of .946. So we would reach the same conclusion as in part a). 


## c)

Next we will use a paired t-test, but first we will check the assumption of normally distributed errors using a qqplot:


```{r}
t <- X-Y

qqnorm(t)
qqline(t)
```

Quantile plots are difficult to interpret, but we see no glaring indication that the differences are not normal. Finally we will perform the test:

```{r, echo = TRUE}
t.test(x=X, y=Y, paired= TRUE, alternative = "greater")
```


With a test statistic of -2.74 and a p-value of .99 we fail to reject the null hypothesis and have no evidence bleed times immediately after ingesting 600 gm of aspirin are greater than bleed times 2 hours after ingesting aspirin.

With modern computing so accessible, I don't see an advantage to using methods based on normal approximations. With the normal approximation p-values are not exact and the assumptions can fail to be realistic.
